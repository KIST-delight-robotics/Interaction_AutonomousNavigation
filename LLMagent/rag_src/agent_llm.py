import rclpy
from rclpy.node import Node
from std_msgs.msg import String

### LangGraph + create_agent
import os
from dotenv import load_dotenv

load_dotenv()
from langchain_teddynote import logging
from langchain_teddynote.messages import stream_response

logging.langsmith("test")
import tiktoken
from langchain.chat_models import init_chat_model

from pydantic import BaseModel
from typing import Literal
from langchain_ollama import ChatOllama
from langchain.agents import create_agent  # âœ… v1ì—ì„œ ì“°ëŠ” í•¨ìˆ˜
from langchain.tools import tool  # v1ì—ì„œ tool ë°ì½”ë ˆì´í„°

from langchain.agents.middleware import wrap_tool_call, SummarizationMiddleware
from langchain_core.messages import ToolMessage, HumanMessage
from langchain.tools import BaseTool
import json
import re

from chat_backends import run_lab_rag, run_general_chat

##############
# RobotCommand ìŠ¤í‚¤ë§ˆ
##############


class RobotCommand(BaseModel):
    intent: Literal[
        "GO",
        "STOP",
        "SET_GOAL",
        "LAB_CHAT",
        "GENERAL_CHAT",
        "NONE"
    ]
    distance_m: float | None = None
    goal: str | None = None
    reply_text: str | None = None   # ëŒ€í™”ìš© TTS ë‚´ìš©


##############
# Tool ì—ëŸ¬ í•¸ë“¤ë§ ë¯¸ë“¤ì›¨ì–´
##############


@wrap_tool_call
def handle_tool_errors(request, handler):
    """ë„êµ¬ ì‹¤í–‰ì„ ì‹œë„í•˜ê³ , ì‹¤íŒ¨í•˜ë©´ LLMì—ê²Œ 'ì‹¤íŒ¨í–ˆë‹¤'ê³  ì•Œë ¤ì¤ë‹ˆë‹¤."""
    try:
        return handler(request)
    except Exception as e:
        print(f"DEBUG: ë„êµ¬ ì˜¤ë¥˜ ë°œìƒ! {e}")
        return ToolMessage(
            content=f"ë„êµ¬ ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: ì…ë ¥ê°’ì„ í™•ì¸í•´ì£¼ì„¸ìš”. (ì˜¤ë¥˜: {str(e)})",
            tool_call_id=request.tool_call["id"],
        )


##############
# ë„êµ¬ ì •ì˜
##############


@tool
def go(distance_m: float = 1.0) -> dict:
    """
    ë¡œë´‡ì„ ì•ìœ¼ë¡œ ì´ë™ì‹œí‚¤ê¸° ìœ„í•œ 'ê³„íš'ì„ ì„¸ìš°ëŠ” íˆ´.
    ì‹¤ì œë¡œ ë¡œë´‡ì„ ì›€ì§ì´ì§€ ì•Šê³ , ì˜ë„ë§Œ ë°˜í™˜í•œë‹¤.

    ë°˜í™˜ í˜•ì‹:
    {
      "command": "go",
      "distance_m": <float>
    }
    """
    print(f"[TOOL] plan_go(distance_m={distance_m})")
    return {"command": "go", "distance_m": distance_m}


@tool
def stop() -> dict:
    """
    ë¡œë´‡ì„ ë©ˆì¶”ê¸° ìœ„í•œ 'ê³„íš'ì„ ì„¸ìš°ëŠ” íˆ´.

    ë°˜í™˜ í˜•ì‹:
    {
      "command": "stop"
    }
    """
    print("[TOOL] plan_stop()")
    return {"command": "stop"}


@tool
def set_goal(goal: str) -> dict:
    """
    ë¡œë´‡ì˜ `ëª©ì ì§€`ë¥¼ ë°”ê¾¸ê¸° ìœ„í•œ íˆ´.
    ëª©ì ì§€ëŠ” ['L0','L1','L2'] ì¤‘ í•˜ë‚˜ê°€ ë  ìˆ˜ ìˆë‹¤.

    ë°˜í™˜ í˜•ì‹:
    {
      "command": "set_goal",
      "goal": "<ëª©ì ì§€>"
    }
    """
    print(f"[TOOL] set_goal(goal={goal})")
    return {"command": "set_goal", "goal": goal}

@tool
def lab_chat(question: str) -> dict:
    """
    KISTì—°êµ¬ì†Œ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•œ ëŒ€í™”ìš© íˆ´.
    RAG íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•œë‹¤.
    """
    print(f"[TOOL] lab_chat(question={question})")
    answer = run_lab_rag(question)
    return {
        "command": "lab_chat",
        "reply": answer
    }


@tool
def general_chat(question: str) -> dict:
    """
    kistì—°êµ¬ì†Œì™€ ìƒê´€ì—†ëŠ” ì¼ë°˜ ëŒ€í™”ë¥¼ ìœ„í•œ íˆ´.
    ê³ ì„±ëŠ¥ LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•œë‹¤.
    """
    print(f"[TOOL] general_chat(question={question})")
    answer = run_general_chat(question)
    return {
        "command": "general_chat",
        "reply": answer
    }


tools = [go, stop, set_goal,lab_chat,general_chat]

##############
# ëª¨ë¸ ì„¤ì •
##############

agent_llm = ChatOllama(model="llama3.1:8b")
#agent_llm = ChatOllama(model="exaone3.5:7.8b")
exa_llm = ChatOllama(model="ingu627/exaone4.0:latest")


##############
# ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
##############

agent_prompt = """
ë„ˆëŠ” ë¡œë´‡ ì œì–´ë¥¼ ìœ„í•œ ReAct ìŠ¤íƒ€ì¼ ì—ì´ì „íŠ¸ì´ë‹¤.

ì‚¬ìš©ìì˜ í•œêµ­ì–´ ëª…ë ¹ì„ ì½ê³ , í•„ìš”í•˜ë©´ ì•„ë˜ ì„¸ ë„êµ¬ ì¤‘
í•˜ë‚˜ ë˜ëŠ” ì—¬ëŸ¬ ê°œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œí•´ì„œ
'ë¡œë´‡ì„ ì–´ë–»ê²Œ ì›€ì§ì¼ì§€ì— ëŒ€í•œ ê³„íš(plan)'ë§Œ ì„¸ìš´ë‹¤.
ì‹¤ì œ ë¡œë´‡ ì œì–´ëŠ” ì´ ê³„íšì„ ì½ëŠ” ë‹¤ë¥¸ ROS ë…¸ë“œ(FSMNode)ê°€ ìˆ˜í–‰í•œë‹¤.

[í˜„ì¬ ìƒíƒœ ì •ë³´]

ì‚¬ìš©ì ì…ë ¥ ì•ì—ëŠ” í•­ìƒ í•œ ì¤„ì§œë¦¬ í˜„ì¬ FSM ìƒíƒœê°€ ë¶™ëŠ”ë‹¤.
í˜•ì‹ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

[í˜„ì¬ìƒíƒœ] base=ING, nav=1, speak=1, monitor=1
ì‚¬ìš©ì ë°œí™”: ë©ˆì¶°ë´

ê° í•„ë“œëŠ” ë‹¤ìŒ ì˜ë¯¸ë¥¼ ê°€ì§„ë‹¤.
- base   : ìƒìœ„ ìƒíƒœ (START/ING/END)
- nav    : 0ì´ë©´ ì •ì§€, 1ì´ë©´ ì£¼í–‰ ì¤‘
- speak  : 0=ìŒì„±ì œì–´ OFF, 1=ëª…ë ¹/ëŒ€í™” ëŒ€ê¸°, 2=TTSë¡œ ë§í•˜ëŠ” ì¤‘
- monitor: 0=ëª¨ë‹ˆí„°ë§ OFF, 1=ON

ë„ˆëŠ” ì´ ìƒíƒœë¥¼ ì°¸ê³ í•´ì„œ ë¶ˆí•„ìš”í•œ ê³„íšì„ í”¼í•´ì•¼ í•œë‹¤.
ì˜ˆë¥¼ ë“¤ì–´:
- nav=1(ì´ë¯¸ ì£¼í–‰ ì¤‘)ì¸ë° ë˜ "ì¡°ê¸ˆë§Œ ë” ê°€ë´"ë¼ê³  í•˜ë©´ goë¥¼ ë‹¤ì‹œ ì¨ë„ ë˜ì§€ë§Œ,
  ë‹¨ìˆœíˆ ê±°ë¦¬ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” goë§Œ í•œ ë²ˆ ì“°ë©´ ëœë‹¤.
- ì´ë¯¸ ì¶©ë¶„íˆ ë©ˆì¶°ìˆëŠ” ìƒí™©(nav=0)ì—ì„œ "ë©ˆì¶°"ë¼ê³  í•˜ë©´ stopì„ êµ³ì´ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•  í•„ìš” ì—†ë‹¤.

[ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡]

1) go
- ê¸°ëŠ¥: ë¡œë´‡ì„ í˜„ì¬ ì§„í–‰ ë°©í–¥ ê¸°ì¤€ìœ¼ë¡œ ì•ìœ¼ë¡œ ì´ë™ì‹œí‚¤ëŠ” ê³„íšì„ ì„¸ìš´ë‹¤.
- íŒŒë¼ë¯¸í„°:
  - distance_m (float, ì„ íƒ): ì „ì§„í•  ê±°ë¦¬(ë¯¸í„°).
    ì˜ˆ: "í•œ 2ë¯¸í„°ë§Œ ê°€ë´", "ì¡°ê¸ˆë§Œ ì•ìœ¼ë¡œ" ê°™ì€ í‘œí˜„ì„ ì ë‹¹í•œ ìˆ˜ì¹˜ë¡œ ë³€í™˜í•´ì„œ ë„£ì–´ë¼.
    ê±°ë¦¬ê°€ ì–¸ê¸‰ë˜ì§€ ì•Šìœ¼ë©´ 1.0ìœ¼ë¡œ ë‘”ë‹¤.

2) stop
- ê¸°ëŠ¥: ë¡œë´‡ì„ ì¦‰ì‹œ ë©ˆì¶”ëŠ” ê³„íšì„ ì„¸ìš´ë‹¤.
- íŒŒë¼ë¯¸í„°: ì—†ìŒ.
- ì˜ˆ: "ë©ˆì¶°", "ìŠ¤íƒ‘", "ê±°ê¸° ì„œ" ë“±.

3) set_goal
- ê¸°ëŠ¥: ë¡œë´‡ì˜ ëª©í‘œ ìœ„ì¹˜(ëª©ì ì§€)ë¥¼ ['L0', 'L1', 'L2'] ì¤‘ í•˜ë‚˜ë¡œ ì„¤ì •í•˜ëŠ” ê³„íšì„ ì„¸ìš´ë‹¤.
- íŒŒë¼ë¯¸í„°:
  - goal (str): 'L0', 'L1', 'L2' ì¤‘ í•˜ë‚˜.

4) lab_chat
- ê¸°ëŠ¥: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì—°êµ¬ì†Œ, ì—°êµ¬ì‹¤, í”„ë¡œì íŠ¸, ì‹¤í—˜ ë‚´ìš©ê³¼ ê´€ë ¨ëœ ê²½ìš°
        RAG ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì •ë³´ë¥¼ ì°¾ì•„ ë‹µë³€í•œë‹¤.
- íŒŒë¼ë¯¸í„°:
  - question (str): ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì „ì²´ ë¬¸ì¥.

5) general_chat
- ê¸°ëŠ¥: ì¼ìƒ ëŒ€í™”, ì¡ë‹´, ì—°êµ¬ì†Œì™€ ë¬´ê´€í•œ ë‚´ìš©ì— ëŒ€í•´ ë‹µë³€í•œë‹¤.
- íŒŒë¼ë¯¸í„°:
  - question (str): ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì „ì²´ ë¬¸ì¥.

[ëŒ€í™” ë„êµ¬ ì„ íƒ ê·œì¹™]
- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì—°êµ¬ì‹¤/ì—°êµ¬ì†Œ, í”„ë¡œì íŠ¸, ì‹¤í—˜ ì¥ë¹„, ì‹¤í—˜ ê²°ê³¼,
  ë…¼ë¬¸, ì—°êµ¬ ë‚´ìš© ë“±ê³¼ ëª…í™•íˆ ê´€ë ¨ë˜ì–´ ìˆë‹¤ë©´ lab_chatì„ ì‚¬ìš©í•˜ë¼.
- ê·¸ ì™¸ ì¼ìƒ ëŒ€í™”, ê°ì •, ë‚ ì”¨, ì‚¬ì ì¸ ê³ ë¯¼ ë“±ì€ general_chatì„ ì‚¬ìš©í•˜ë¼.


[ì¤‘ìš” ì§€ì¹¨]

- ë„êµ¬ë¥¼ ì „í˜€ ì“°ì§€ ì•Šì•„ë„ ëœë‹¤ê³  íŒë‹¨ë˜ë©´, íˆ´ì„ í˜¸ì¶œí•˜ì§€ ì•Šê³  ìì—°ì–´ ë‹µë³€ë§Œ í•´ë„ ëœë‹¤.
- í•˜ì§€ë§Œ ì´ë™/ì •ì§€/ëª©ì ì§€ ë³€ê²½ê³¼ ê´€ë ¨ëœ ë°œí™”ë¼ë©´ ë°˜ë“œì‹œ ì ì ˆí•œ ë„êµ¬(go/stop/set_goal)ë¥¼ ì‚¬ìš©í•´ ê³„íšì„ ë§Œë“ ë‹¤.
- ë§ˆì§€ë§‰ì— ì‚¬ìš©ëœ ë„êµ¬ì˜ ì¶œë ¥ì´ ìµœì¢…ì ì¸ ë¡œë´‡ ê³„íšìœ¼ë¡œ ì‚¬ìš©ëœë‹¤.
"""


print("ğŸ” ChatOllama model =", getattr(agent_llm, "model", None))
print("ğŸ” ChatOllama default params =", getattr(agent_llm, "_default_params", None))

agent = create_agent(
    model=agent_llm,
    tools=tools,
    middleware=[handle_tool_errors],
    system_prompt=agent_prompt,
)


class LLMAgentNode(Node):
    """
    LLM ì—ì´ì „íŠ¸ê°€ ë§Œë“  RobotCommandë¥¼ ROS í† í”½ìœ¼ë¡œ ë°œí–‰í•˜ëŠ” ë…¸ë“œ
    """

    def __init__(self):
        super().__init__("llm_agent_node")

        # RobotCommandë¥¼ JSONìœ¼ë¡œ ë°œí–‰í•˜ëŠ” í† í”½
        self.cmd_pub = self.create_publisher(
            String,
            "/llm/selected_tool",
            10,
        )

        # FSM ìƒíƒœ ìºì‹œ
        self.last_fsm_state = {
            "base": "START",
            "nav": 0,
            "speak": 0,
            "monitor": 0,
        }

        # FSM ìƒíƒœ êµ¬ë…
        self.state_sub = self.create_subscription(
            String,
            "/fsm/state",
            self.fsm_state_callback,
            10,
        )
        self.stt_sub = self.create_subscription(
            String,
            "/user_question",          # ì˜ˆ: STT ë…¸ë“œê°€ ë°œí–‰í•˜ëŠ” í…ìŠ¤íŠ¸ í† í”½
            self.stt_callback,
            10,
        )

        self.get_logger().info("âœ… LLMAgentNode ì´ˆê¸°í™” ì™„ë£Œ")

    def fsm_state_callback(self, msg: String):
        try:
            self.last_fsm_state = json.loads(msg.data)
            self.get_logger().info(
                f"[LLMAgentNode]  ğŸ¤– FSM state ì—…ë°ì´íŠ¸: {self.last_fsm_state}"
            )
        except json.JSONDecodeError as e:
            self.get_logger().error(f"[LLMAgentNode] FSM state JSON íŒŒì‹± ì—ëŸ¬: {e}")
    def stt_callback(self, msg: String):
        """
        STT / í…ìŠ¤íŠ¸ í† í”½ìœ¼ë¡œë¶€í„° ë¬¸ì¥ì„ ë°›ì•˜ì„ ë•Œ í˜¸ì¶œë˜ëŠ” ì½œë°±.
        ì´ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ LLM ì—ì´ì „íŠ¸ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.
        """
        user_text = msg.data.strip()
        if not user_text:
            return

        self.get_logger().info(f"[LLMAgentNode] ğŸ¤ STT ì…ë ¥ ìˆ˜ì‹ : {user_text}")

        # ğŸ”¹ í˜„ì¬ FSM ìƒíƒœ + user_textë¥¼ í•©ì³ì„œ ì—ì´ì „íŠ¸ ì‹¤í–‰
        cmd, final_text, _ = self.run_agent_with_state(user_text)

        # run_agent_with_state() ì•ˆì—ì„œ ì´ë¯¸ publish_command(cmd)ë¥¼ í˜¸ì¶œí•˜ê³  ìˆìœ¼ë¯€ë¡œ
        # ì—¬ê¸°ì„œëŠ” ë¡œê·¸ë§Œ ì°ì–´ì¤˜ë„ ëœë‹¤.
        self.get_logger().info(f"[LLMAgentNode] ğŸ¤– RobotCommand: {cmd}")
        self.get_logger().info(f"[LLMAgentNode] ğŸ—¨ï¸ LLM ì‘ë‹µ: {final_text}")

    def publish_command(self, cmd: RobotCommand):
        """
        RobotCommand ê°ì²´ë¥¼ JSON Stringìœ¼ë¡œ ë³€í™˜í•´ì„œ publish
        """
        data = cmd.model_dump()
        msg = String()
        msg.data = json.dumps(data, ensure_ascii=False)
        self.cmd_pub.publish(msg)
        self.get_logger().info(f"[LLMAgentNode] /llm/selected_tool ë°œí–‰: {msg.data}")

    def run_agent_with_state(self, user_text: str):
        """
        FSM ìƒíƒœë¥¼ ì‚¬ìš©ì ë°œí™” ì•ì— ë¶™ì—¬ì„œ LLMì—ê²Œ ë„˜ê¸°ê¸°.
        ì´ë ‡ê²Œ í•˜ë©´ LLMì´ í˜„ì¬ nav/speak/monitor ìƒíƒœë¥¼ ë³´ê³ 
        go/stop/set_goal ì‚¬ìš© ì—¬ë¶€ë¥¼ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•  ìˆ˜ ìˆë‹¤.
        """
        s = self.last_fsm_state
        state_str = (
            f"[í˜„ì¬ìƒíƒœ] base={s['base']}, nav={s['nav']}, "
            f"speak={s['speak']}, monitor={s['monitor']}"
        )
        full_input = state_str + "\nì‚¬ìš©ì ë°œí™”: " + user_text

        cmd, final_text, meta = run_agent(full_input)
        self.publish_command(cmd)
        return cmd, final_text, meta


#################
# Tool ê²°ê³¼ â†’ RobotCommandë¡œ ë³€í™˜
#################


def extract_last_plan(messages) -> RobotCommand:
    """
    messages ë¦¬ìŠ¤íŠ¸ì—ì„œ ë§ˆì§€ë§‰ ToolMessageë¥¼ ì°¾ì•„ì„œ
    RobotCommandë¡œ ë°”ê¿”ì¤€ë‹¤.
    ToolMessageê°€ ì—†ìœ¼ë©´ intent=NONEì„ ë¦¬í„´.
    """
    last_tool_msg: ToolMessage | None = None

    for m in reversed(messages):
        if m.type == "tool":
            last_tool_msg = m
            break

    if last_tool_msg is None:
        # íˆ´ì„ ì•„ì˜ˆ ì•ˆ ì¼ìœ¼ë©´ ì œì–´ ëª…ë ¹ì´ ì•„ë‹ˆë¼ê³  ë³´ê³  NONE
        return RobotCommand(intent="NONE")

    data = last_tool_msg.content  # go/stop/set_goalì´ ë°˜í™˜í•œ dict

    if isinstance(data, str):
        try:
            data = json.loads(data)
        except Exception:
            data = {"command": "unknown"}

    cmd = data.get("command")

    if cmd == "go":
        return RobotCommand(
            intent="GO",
            distance_m=data.get("distance_m"),
        )
    elif cmd == "stop":
        return RobotCommand(intent="STOP")
    elif cmd == "set_goal":
        return RobotCommand(
            intent="SET_GOAL",
            goal=data.get("goal"),
        )
    elif cmd == "lab_chat":
        return RobotCommand(
            intent="LAB_CHAT",
            reply_text=data.get("reply")
        )
    elif cmd == "general_chat":
        return RobotCommand(
            intent="GENERAL_CHAT",
            reply_text=data.get("reply")
        )
    else:
        return RobotCommand(intent="NONE")



def run_agent(user_text: str):
    state = agent.invoke({"messages": [HumanMessage(content=user_text)]})
    messages = state["messages"]

    print("\n========== [DEBUG] ë©”ì‹œì§€ íƒ€ì„ë¼ì¸ ==========")
    for m in messages:
        print(type(m), " | ", m.type, " | ", getattr(m, "name", None), " | ", m.content)
        if getattr(m, "tool_calls", None):
            print("  â†³ tool_calls:", m.tool_calls)
    print("============================================\n")

    # 1) íˆ´ ê¸°ë°˜ ê³„íš â†’ RobotCommand ë¡œ ë³€í™˜
    robot_cmd = extract_last_plan(messages)

    # ë§ˆì§€ë§‰ ìì—°ì–´ AI ì‘ë‹µ + usage_metadata ì°¾ê¸°
    final_text = None
    last_ai_usage = None

    for m in reversed(messages):
        if m.type == "ai" and not getattr(m, "tool_calls", None):
            final_text = m.content
            last_ai_usage = getattr(m, "usage_metadata", None)
            break

    if final_text is None:
        last_msg = messages[-1]
        final_text = last_msg.content
        last_ai_usage = getattr(last_msg, "usage_metadata", None)

    return robot_cmd, final_text, last_ai_usage


# 5. ë©”ì¸ ë£¨í”„: í•œ ë²ˆ í…ŒìŠ¤íŠ¸ + ì¸í„°ë™í‹°ë¸Œ ----------------------------

if __name__ == "__main__":
    rclpy.init()
    node = LLMAgentNode()

    try:
        # ğŸ”¹ ì´ì œëŠ” /user_question í† í”½ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ë°›ê¸°ë§Œ í•˜ë©´ ë˜ë¯€ë¡œ
        #     ê·¸ëƒ¥ spin ìœ¼ë¡œ ì½œë°±ë§Œ ëŒë ¤ì£¼ë©´ ëœë‹¤.
        rclpy.spin(node)

    except KeyboardInterrupt:
        node.get_logger().info("LLMAgentNode ì¢…ë£Œ (Ctrl+C)")

    finally:
        node.destroy_node()
        rclpy.shutdown()

